#!/usr/bin/env python3
"""
ğŸ“Š RAS Commander Results Processing Module
==========================================

MÃ³dulo especializado para el procesamiento de resultados HEC-RAS usando RAS Commander.
Proporciona funcionalidades avanzadas para anÃ¡lisis de resultados de simulaciones hidrÃ¡ulicas.

Funcionalidades principales:
- Procesamiento de resultados de mallas 2D
- AnÃ¡lisis de series temporales
- ExtracciÃ³n de valores mÃ¡ximos y mÃ­nimos
- AnÃ¡lisis estadÃ­stico de resultados
- Procesamiento de resultados de secciones transversales

Autor: eFlood2 Technologies
VersiÃ³n: 0.1.0
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# IMPORTS Y CONFIGURACIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import json
import logging
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union

import geopandas as gpd
import numpy as np
import pandas as pd

# RAS Commander imports
try:
    from ras_commander import (
        HdfMesh,
        HdfPlan,
        HdfResultsMesh,
        HdfResultsPlan,
        HdfResultsXsec,
    )

    RAS_COMMANDER_AVAILABLE = True
except ImportError:
    RAS_COMMANDER_AVAILABLE = False

# Imports locales
from .commander_utils import (
    convert_numpy_types,
    create_result_dict,
    handle_ras_exceptions,
    logger,
    ras_commander_required,
    safe_json_serialize,
    validate_hdf_file,
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLASE PRINCIPAL PARA PROCESAMIENTO DE RESULTADOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class CommanderResultsProcessor:
    """
    ğŸ“Š Procesador de resultados HEC-RAS usando RAS Commander.

    Proporciona funcionalidades avanzadas para el anÃ¡lisis y procesamiento
    de resultados de simulaciones hidrÃ¡ulicas HEC-RAS.
    """

    def __init__(self, hdf_file_path: str):
        """
        Inicializa el procesador de resultados.

        Args:
            hdf_file_path: Ruta al archivo HDF de HEC-RAS
        """
        self.hdf_file_path = hdf_file_path
        self.validation_result = validate_hdf_file(hdf_file_path)

        if not self.validation_result["success"]:
            logger.error(
                f"Error validando archivo HDF: {self.validation_result['error']}"
            )

    @ras_commander_required
    @handle_ras_exceptions
    def get_maximum_results_analysis(self) -> Dict[str, Any]:
        """
        Obtiene anÃ¡lisis completo de resultados mÃ¡ximos del modelo.

        Returns:
            Dict con anÃ¡lisis de resultados mÃ¡ximos
        """
        if not self.validation_result["success"]:
            return self.validation_result

        try:
            results_analysis = {
                "max_water_surface": self._analyze_max_water_surface(),
                "max_velocity": self._analyze_max_velocity(),
                "max_depth": self._analyze_max_depth(),
                "max_ws_error": self._analyze_max_ws_error(),
            }

            # Contar elementos procesados
            total_elements = sum(
                analysis.get("element_count", 0)
                for analysis in results_analysis.values()
                if isinstance(analysis, dict)
            )

            logger.info(
                f"AnÃ¡lisis de resultados mÃ¡ximos completado: {total_elements} elementos"
            )

            return create_result_dict(
                success=True,
                data={
                    "total_elements_analyzed": total_elements,
                    "analysis_timestamp": datetime.now().isoformat(),
                    "results_by_type": results_analysis,
                },
                message=f"AnÃ¡lisis de resultados mÃ¡ximos completado para {total_elements} elementos",
            )

        except Exception as e:
            raise e

    @ras_commander_required
    @handle_ras_exceptions
    def get_time_series_analysis(
        self, mesh_name: str, variable: str = "Water Surface"
    ) -> Dict[str, Any]:
        """
        Realiza anÃ¡lisis de series temporales para una malla especÃ­fica.

        Args:
            mesh_name: Nombre de la malla a analizar
            variable: Variable a analizar (ej: "Water Surface", "Velocity")

        Returns:
            Dict con anÃ¡lisis de series temporales
        """
        if not self.validation_result["success"]:
            return self.validation_result

        try:
            # Obtener datos de series temporales
            timeseries_data = HdfResultsMesh.get_mesh_timeseries(
                self.hdf_file_path, mesh_name, variable
            )

            if timeseries_data is None or timeseries_data.empty:
                return create_result_dict(
                    success=False,
                    error=f"No se encontraron datos de series temporales para {mesh_name} - {variable}",
                )

            # Realizar anÃ¡lisis estadÃ­stico
            analysis = {
                "mesh_name": mesh_name,
                "variable": variable,
                "data_shape": timeseries_data.shape,
                "time_steps": len(timeseries_data),
                "columns": list(timeseries_data.columns),
                "has_geometry": hasattr(timeseries_data, "geometry"),
                "statistics": {},
                "temporal_analysis": {},
            }

            # EstadÃ­sticas bÃ¡sicas
            numeric_cols = timeseries_data.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                stats_dict = timeseries_data[numeric_cols].describe().to_dict()
                analysis["statistics"] = convert_numpy_types(stats_dict)

                # AnÃ¡lisis temporal adicional
                analysis["temporal_analysis"] = self._perform_temporal_analysis(
                    timeseries_data[numeric_cols]
                )

            logger.info(
                f"AnÃ¡lisis de series temporales completado: {mesh_name} - {variable}"
            )

            return create_result_dict(
                success=True,
                data=analysis,
                message=f"AnÃ¡lisis de series temporales completado para {mesh_name} - {variable}",
            )

        except Exception as e:
            raise e

    @ras_commander_required
    @handle_ras_exceptions
    def get_cross_section_results(self) -> Dict[str, Any]:
        """
        Obtiene resultados de secciones transversales.

        Returns:
            Dict con resultados de secciones transversales
        """
        if not self.validation_result["success"]:
            return self.validation_result

        try:
            # Obtener resultados de secciones transversales usando RAS Commander
            xsec_analysis = {
                "total_cross_sections": 0,
                "cross_sections_data": [],
                "summary_statistics": {},
            }

            # Implementar anÃ¡lisis especÃ­fico de secciones transversales
            # Nota: La implementaciÃ³n especÃ­fica depende de los mÃ©todos disponibles en HdfResultsXsec

            logger.info("AnÃ¡lisis de secciones transversales completado")

            return create_result_dict(
                success=True,
                data=xsec_analysis,
                message="AnÃ¡lisis de secciones transversales completado",
            )

        except Exception as e:
            raise e

    @ras_commander_required
    @handle_ras_exceptions
    def export_results_summary(self, output_path: str) -> Dict[str, Any]:
        """
        Exporta un resumen completo de resultados a archivo.

        Args:
            output_path: Ruta del archivo de salida

        Returns:
            Dict con resultado de la exportaciÃ³n
        """
        if not self.validation_result["success"]:
            return self.validation_result

        try:
            # Obtener anÃ¡lisis completo
            max_results = self.get_maximum_results_analysis()

            # Preparar resumen para exportaciÃ³n
            summary = {
                "export_timestamp": datetime.now().isoformat(),
                "hdf_file": self.hdf_file_path,
                "maximum_results_analysis": max_results.get("data", {}),
                "export_info": {
                    "generated_by": "eFlood2 RAS Commander Integration",
                    "version": "0.1.0",
                },
            }

            # Exportar a archivo JSON
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)

            logger.info(f"Resumen de resultados exportado a: {output_path}")

            return create_result_dict(
                success=True,
                data={
                    "output_file": output_path,
                    "file_size_kb": round(os.path.getsize(output_path) / 1024, 2),
                    "summary_elements": len(summary),
                },
                message=f"Resumen exportado exitosamente a {output_path}",
            )

        except Exception as e:
            raise e

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MÃ‰TODOS PRIVADOS DE ANÃLISIS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _analyze_max_water_surface(self) -> Dict[str, Any]:
        """Analiza resultados mÃ¡ximos de superficie de agua."""
        try:
            max_ws_gdf = HdfResultsMesh.get_mesh_max_ws(self.hdf_file_path)

            if max_ws_gdf is None or max_ws_gdf.empty:
                return {
                    "element_count": 0,
                    "error": "No se encontraron datos de superficie mÃ¡xima",
                }

            analysis = {
                "element_count": len(max_ws_gdf),
                "columns": list(max_ws_gdf.columns),
                "has_geometry": hasattr(max_ws_gdf, "geometry"),
            }

            # EstadÃ­sticas si hay datos numÃ©ricos
            numeric_cols = max_ws_gdf.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                stats = max_ws_gdf[numeric_cols].describe().to_dict()
                analysis["statistics"] = convert_numpy_types(stats)

            return analysis

        except Exception as e:
            return {"error": f"Error analizando superficie mÃ¡xima: {str(e)}"}

    def _analyze_max_velocity(self) -> Dict[str, Any]:
        """Analiza resultados mÃ¡ximos de velocidad."""
        try:
            max_vel_gdf = HdfResultsMesh.get_mesh_max_face_v(self.hdf_file_path)

            if max_vel_gdf is None or max_vel_gdf.empty:
                return {
                    "element_count": 0,
                    "error": "No se encontraron datos de velocidad mÃ¡xima",
                }

            analysis = {
                "element_count": len(max_vel_gdf),
                "columns": list(max_vel_gdf.columns),
                "has_geometry": hasattr(max_vel_gdf, "geometry"),
            }

            # EstadÃ­sticas si hay datos numÃ©ricos
            numeric_cols = max_vel_gdf.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                stats = max_vel_gdf[numeric_cols].describe().to_dict()
                analysis["statistics"] = convert_numpy_types(stats)

            return analysis

        except Exception as e:
            return {"error": f"Error analizando velocidad mÃ¡xima: {str(e)}"}

    def _analyze_max_depth(self) -> Dict[str, Any]:
        """Analiza resultados mÃ¡ximos de profundidad."""
        try:
            max_depth_gdf = HdfResultsMesh.get_mesh_max_depth(self.hdf_file_path)

            if max_depth_gdf is None or max_depth_gdf.empty:
                return {
                    "element_count": 0,
                    "error": "No se encontraron datos de profundidad mÃ¡xima",
                }

            analysis = {
                "element_count": len(max_depth_gdf),
                "columns": list(max_depth_gdf.columns),
                "has_geometry": hasattr(max_depth_gdf, "geometry"),
            }

            # EstadÃ­sticas si hay datos numÃ©ricos
            numeric_cols = max_depth_gdf.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                stats = max_depth_gdf[numeric_cols].describe().to_dict()
                analysis["statistics"] = convert_numpy_types(stats)

            return analysis

        except Exception as e:
            return {"error": f"Error analizando profundidad mÃ¡xima: {str(e)}"}

    def _analyze_max_ws_error(self) -> Dict[str, Any]:
        """Analiza errores mÃ¡ximos de superficie de agua."""
        try:
            max_ws_err_gdf = HdfResultsMesh.get_mesh_max_ws_err(self.hdf_file_path)

            if max_ws_err_gdf is None or max_ws_err_gdf.empty:
                return {
                    "element_count": 0,
                    "error": "No se encontraron datos de error de superficie",
                }

            analysis = {
                "element_count": len(max_ws_err_gdf),
                "columns": list(max_ws_err_gdf.columns),
                "has_geometry": hasattr(max_ws_err_gdf, "geometry"),
            }

            # EstadÃ­sticas si hay datos numÃ©ricos
            numeric_cols = max_ws_err_gdf.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                stats = max_ws_err_gdf[numeric_cols].describe().to_dict()
                analysis["statistics"] = convert_numpy_types(stats)

            return analysis

        except Exception as e:
            return {"error": f"Error analizando error de superficie: {str(e)}"}

    def _perform_temporal_analysis(self, numeric_data: pd.DataFrame) -> Dict[str, Any]:
        """
        Realiza anÃ¡lisis temporal adicional en datos numÃ©ricos.

        Args:
            numeric_data: DataFrame con datos numÃ©ricos

        Returns:
            Dict con anÃ¡lisis temporal
        """
        try:
            temporal_stats = {}

            for column in numeric_data.columns:
                series = numeric_data[column].dropna()
                if len(series) > 1:
                    temporal_stats[column] = {
                        "trend": (
                            "increasing"
                            if series.iloc[-1] > series.iloc[0]
                            else "decreasing"
                        ),
                        "volatility": float(series.std()),
                        "range": float(series.max() - series.min()),
                        "peak_time_step": (
                            int(series.idxmax()) if not series.empty else None
                        ),
                    }

            return convert_numpy_types(temporal_stats)

        except Exception as e:
            return {"error": f"Error en anÃ¡lisis temporal: {str(e)}"}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIONES DE UTILIDAD PARA USO DIRECTO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


@ras_commander_required
@handle_ras_exceptions
def quick_max_results_analysis(hdf_file_path: str) -> Dict[str, Any]:
    """
    AnÃ¡lisis rÃ¡pido de resultados mÃ¡ximos.

    Args:
        hdf_file_path: Ruta al archivo HDF

    Returns:
        Dict con anÃ¡lisis de resultados mÃ¡ximos
    """
    processor = CommanderResultsProcessor(hdf_file_path)
    return processor.get_maximum_results_analysis()


@ras_commander_required
@handle_ras_exceptions
def quick_timeseries_analysis(
    hdf_file_path: str, mesh_name: str, variable: str = "Water Surface"
) -> Dict[str, Any]:
    """
    AnÃ¡lisis rÃ¡pido de series temporales.

    Args:
        hdf_file_path: Ruta al archivo HDF
        mesh_name: Nombre de la malla
        variable: Variable a analizar

    Returns:
        Dict con anÃ¡lisis de series temporales
    """
    processor = CommanderResultsProcessor(hdf_file_path)
    return processor.get_time_series_analysis(mesh_name, variable)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIÃ“N PRINCIPAL PARA TESTING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def main():
    """
    FunciÃ³n principal para testing del mÃ³dulo commander_results.
    """
    print("ğŸ“Š RAS Commander Results Processor - Test Mode")
    print("=" * 60)

    if len(sys.argv) < 2:
        print("Uso: python commander_results.py <hdf_file_path> [mesh_name] [variable]")
        return

    hdf_file_path = sys.argv[1]
    mesh_name = sys.argv[2] if len(sys.argv) > 2 else "2D Area 1"
    variable = sys.argv[3] if len(sys.argv) > 3 else "Water Surface"

    # Test del procesador de resultados
    processor = CommanderResultsProcessor(hdf_file_path)

    # Test de anÃ¡lisis de resultados mÃ¡ximos
    print("Analizando resultados mÃ¡ximos...")
    max_results = processor.get_maximum_results_analysis()
    print(f"Resultados mÃ¡ximos: {safe_json_serialize(max_results)}")

    # Test de anÃ¡lisis de series temporales
    print(f"\nAnalizando series temporales: {mesh_name} - {variable}")
    timeseries_result = processor.get_time_series_analysis(mesh_name, variable)
    print(f"Series temporales: {safe_json_serialize(timeseries_result)}")


if __name__ == "__main__":
    main()
